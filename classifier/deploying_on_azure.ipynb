{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/aaditya/PycharmProjects/Codefundopp/classifier/aml_config/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception_1\txception_1:5\t5\nCPU times: user 378 ms, sys: 33.8 ms, total: 412 ms\nWall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.model import Model\n",
    "from classifier.create_ws import AZHelper\n",
    "import os\n",
    "\n",
    "ws = AZHelper.load_ws()\n",
    "model=Model(ws, 'xception_1')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n# be automatically provisioned for runs with userManagedDependencies=False.\r\n\n# Details about the Conda environment file format:\r\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\r\n  # Currently Azure ML only supports 3.5.2 and later.\r\n- python=3.6.2\n\n- pip:\n  - azureml-defaults==1.0.8\n  - torch\n  - torchvision\n\n"
     ]
    }
   ],
   "source": [
    "# test(xp, test_dl)\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=['azureml-defaults', 'torch', 'torchvision'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scoring_on_azure.py'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('classifier/scoring_on_azure.py', 'scoring_on_azure.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('classifier/scoring_on_azure.py', 'scoring_on_azure.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Image\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# image_config = ContainerImage.image_configuration(execution_script='scoring_on_azure.py', \n",
    "#                                                   runtime='python', \n",
    "#                                                   conda_file='myenv.yml',\n",
    "#                                                   description='Working image with xception model')\n",
    "\n",
    "# create the image\n",
    "# image = Image.create(name='xception-wildfire', models=[model], image_config=image_config, workspace=ws)\n",
    "\n",
    "# wait for image creation to finish\n",
    "# image.wait_for_creation(show_output=True)\n",
    "image = Image(ws, name='xception-wildfire', version='1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=4, \n",
    "                                               tags={'data': 'wildfire',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Classify wildfire/not_wildfire using transfer learning with PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\nSucceeded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\nCPU times: user 2.31 s, sys: 86.8 ms, total: 2.39 s\nWall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'aci-wildfire'\n",
    "service = Webservice.deploy_from_image(workspace=ws,\n",
    "                                       name=service_name,\n",
    "                                       image=image,\n",
    "                                       deployment_config=aciconfig,)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://104.45.178.57:80/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-21T19:50:15,011427610+00:00 - nginx/run \n2019-01-21T19:50:15,012221114+00:00 - iot-server/run \nok: run: gunicorn: (pid 12) 0s\nok: run: rsyslog: (pid 14) 0s\nok: run: nginx: (pid 11) 0s\nok: run: rsyslog: (pid 14) 0s\n2019-01-21T19:50:15,018739742+00:00 - gunicorn/run \nok: run: rsyslog: (pid 14) 0s\n2019-01-21T19:50:15,040396537+00:00 - rsyslog/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2019-01-21T19:50:15,159009855+00:00 - iot-server/finish 1 0\n2019-01-21T19:50:15,159991559+00:00 - Exit code 1 is normal. Not restarting iot-server.\n{\"timestamp\": \"2019-01-21T19:50:15.379525Z\", \"message\": \"Starting gunicorn 19.6.0\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Starting gunicorn %s\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:15.380485Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (12)\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Listening at: %s (%s)\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:15.380592Z\", \"message\": \"Using worker: sync\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Using worker: %s\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:15.381198Z\", \"message\": \"worker timeout is set to 300\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:15.382191Z\", \"message\": \"Booting worker with pid: 39\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Booting worker with pid: %s\", \"stack_info\": null}\nInitializing logger\n{\"timestamp\": \"2019-01-21T19:50:17.918092Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insights client\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:17.918300Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up request id generator\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:17.918404Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insight hooks\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:17.918502Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Invoking user's init function\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n2019-01-21 19:50:17,919 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run., switching offline: False\n2019-01-21 19:50:17,919 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n2019-01-21 19:50:17,919 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n2019-01-21 19:50:17,919 | azureml.core.model | DEBUG | version is None. Latest version is 4\n2019-01-21 19:50:17,919 | azureml.core.model | DEBUG | Found model path at azureml-models/xception_1/4/xception_train_full.pth\n{\"timestamp\": \"2019-01-21T19:50:17.920089Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"User's init function failed\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"ERROR\", \"logger\": \"root\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:17.920574Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Encountered Exception Traceback (most recent call last):\\\\n  File \\\\\\\"/var/azureml-app/aml_blueprint.py\\\\\\\", line 109, in register\\\\n    main.init()\\\\n  File \\\\\\\"/var/azureml-app/main.py\\\\\\\", line 79, in init\\\\n    driver_module.init()\\\\n  File \\\\\\\"scoring_on_azure.py\\\\\\\", line 12, in init\\\\n    model = torch.load(model_path)\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/site-packages/torch/serialization.py\\\\\\\", line 367, in load\\\\n    return _load(f, map_location, pickle_module)\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/site-packages/torch/serialization.py\\\\\\\", line 538, in _load\\\\n    result = unpickler.load()\\\\nModuleNotFoundError: No module named 'xception'\\\\n\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"ERROR\", \"logger\": \"root\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:17.920733Z\", \"message\": \"Worker exiting (pid: 39)\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Worker exiting (pid: %s)\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:18.075804Z\", \"message\": \"Shutting down: Master\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Shutting down: %s\", \"stack_info\": null}\n{\"timestamp\": \"2019-01-21T19:50:18.076105Z\", \"message\": \"Reason: Worker failed to boot.\", \"host\": \"wk-caas-711866e6262844688b9f7374690d3618-cf85ff94e073dc94d8b912\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Reason: %s\", \"stack_info\": null}\n2019-01-21T19:50:18,097545485+00:00 - gunicorn/finish 3 0\n2019-01-21T19:50:18,098916091+00:00 - Exit code 3 is not normal. Killing image.\n\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models/xception_1/4/xception_train_full.pth\n"
     ]
    }
   ],
   "source": [
    "print(Model.get_model_path(model_name='xception_1', _workspace=ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACI'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service._webservice_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
